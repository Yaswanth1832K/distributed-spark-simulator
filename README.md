<div align="center">

# âš¡ ClusterFlow
### Distributed Spark Simulator â€” V2.0

**A real-time, full-stack distributed systems simulator built with Apache Spark, Python Flask, and React.**
Visualize data partitioning, inject node failures, and observe self-healing fault tolerance â€” live.

[![React](https://img.shields.io/badge/React-19-61DAFB?style=for-the-badge&logo=react&logoColor=black)](https://react.dev/)
[![Python](https://img.shields.io/badge/Python-Flask-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://flask.palletsprojects.com/)
[![Apache Spark](https://img.shields.io/badge/Apache_Spark-3.5-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)](https://spark.apache.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](LICENSE)

</div>

---

## ğŸŒ Overview

ClusterFlow is a **hybrid distributed computing platform** that brings the internals of Apache Spark to life through a premium, interactive dashboard. It demonstrates the core concepts of distributed systems â€” including data partitioning, parallel execution, load balancing, and fault tolerance â€” in a visual and intuitive way.

Think of it as a **"Flight Simulator" for Big Data Engineering**: you set up a cluster, submit jobs, inject failures, and watch the system self-heal in real time.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Windows Host      â”‚           â”‚   WSL Ubuntu (Linux) â”‚
â”‚                     â”‚           â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ React UI      â”‚  â”‚  HTTP/    â”‚  â”‚ Flask API      â”‚ â”‚
â”‚  â”‚ (Port 5173)   â”‚  â”‚  REST     â”‚  â”‚ (Port 5000)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                     â”‚           â”‚           â”‚PySpark  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚
                                  â”‚  â”‚ Spark Master   â”‚ â”‚
                                  â”‚  â”‚ + Workers      â”‚ â”‚
                                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Layer | Technology | Purpose |
|---|---|---|
| **Frontend** | React 19 + Vite + Tailwind CSS | Interactive dashboard & visualizations |
| **Backend** | Python Flask + Flask-CORS | REST API & Distributed Engine |
| **Compute** | Apache Spark 3.5 + PySpark | Real distributed job execution |
| **Animations** | Framer Motion | Smooth task migration & chaos UI |

---

## âœ¨ Features

- **ğŸ›ï¸ Job Orchestration Matrix** â€” Submit jobs and watch each data partition processed in real time across the cluster, animated live.
- **ğŸ”¥ Chaos Engineering Panel** â€” Kill, slow down, or recover worker nodes on demand to observe fault injection.
- **ğŸ“‹ System Audit Log** â€” A real-time "black box" log that records every decision the Master engine makes.
- **ğŸ›¡ï¸ Fault Tolerance Demo** â€” Tasks on a failed node are automatically detected, logged, and re-queued to a healthy worker.
- **ğŸ“Š Live Cluster Metrics** â€” Per-node CPU usage, memory load, and active task tracking refreshing at sub-second intervals.
- **âš¡ Real Spark Results** â€” Jobs are executed on a real Apache Spark context, with results verified and displayed in the UI.

---

## ğŸš€ Getting Started

### Prerequisites
- Windows with WSL2 (Ubuntu 22.04+)
- Node.js v18+ (Windows)
- Python 3.10+ with `pip` (WSL)
- Apache Spark 3.5 installed in WSL (`~/spark`)
- Java 11+ in WSL

---

### 1. Start the Spark Cluster (WSL)

Open your **WSL Ubuntu terminal**:

```bash
cd ~/spark/sbin

# Launch the master node
./start-master.sh

# Launch a worker node (replace hostname if needed)
./start-worker.sh spark://localhost:7077
```

Spark Master UI: **[http://localhost:8080](http://localhost:8080)**

---

### 2. Start the Backend (WSL)

```bash
cd /mnt/c/path/to/distributed-spark-simulator/backend

# Create and activate a virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install flask flask-cors pyspark findspark

# Run the API server
python app.py
```

API: **[http://localhost:5000](http://localhost:5000)**

---

### 3. Start the Frontend (Windows PowerShell)

```powershell
cd .\frontend

# Install packages
npm install

# Start the dev server
npm run dev
```

Dashboard: **[http://localhost:5173](http://localhost:5173)**

---

## ğŸ® Usage Guide

| Page | What it does |
|---|---|
| **Strategic Hub** | Landing page with live engine status indicator |
| **Orchestration** | Submit jobs, configure partitions, watch the live compute matrix |
| **Surveillance** | Monitor node health, inject failures, read the audit log |

### ğŸ§ª Fault Tolerance Experiment
1. Go to **Orchestration** â†’ Set partitions to **20** â†’ Click **Execute Dispatch**
2. Immediately switch to **Surveillance**
3. When progress hits ~30%, click the **Skull ğŸ’€ icon** on any worker
4. Watch the **Audit Log** fire a `FAULT_DETECTED` event and the affected tasks migrate to a healthy node automatically

---

## ğŸ”§ Troubleshooting

| Problem | Solution |
|---|---|
| `JavaPackage not callable` | Install `findspark` and ensure `SPARK_HOME=~/spark` is set in `~/.bashrc` |
| `Connection refused (port 5000)` | Ensure the Flask backend is running in WSL and bound to `0.0.0.0` |
| `Engine Offline` status in UI | Backend is not running. Restart `python app.py` in WSL |
| Tasks finish too fast to observe | Click **Randomize** to generate a 2000-item dataset, then run the job |

---

## ğŸ“ Project Structure

```
distributed-spark-simulator/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app.py              # Flask API, Distributed Engine, Chaos & Audit logic
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.jsx        # Strategic Hub (landing)
â”‚   â”‚   â”‚   â”œâ”€â”€ Processing.jsx  # Job Orchestration Matrix
â”‚   â”‚   â”‚   â””â”€â”€ Monitor.jsx     # Surveillance & Chaos Panel
â”‚   â”‚   â”œâ”€â”€ App.jsx             # Root layout & sidebar navigation
â”‚   â”‚   â””â”€â”€ index.css           # Global design system & tokens
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md
```

---

## ğŸ“„ License

Distributed under the MIT License. See `LICENSE` for more information.

---

<div align="center">
  Built with â¤ï¸ to demonstrate the power of Distributed Systems.
</div>
